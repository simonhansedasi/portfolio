{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2cf04ab",
   "metadata": {},
   "source": [
    "## Import dependancies and set environment determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c23984e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "#     tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(\n",
    "    0\n",
    ")\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "SEED = 378\n",
    "# SEED = 123\n",
    "print(SEED)\n",
    "def set_seeds(seed=SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_global_determinism(seed=SEED):\n",
    "    set_seeds(seed=seed)\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Call the above function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc684ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glacierml as gl\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tqdm import tqdm\n",
    "import path_manager as pm\n",
    "[\n",
    "        home_path, data_path, RGI_path, glathida_path, \n",
    "        ref_path, coregistration_testing_path, \n",
    "        arch_test_path, LOO_path\n",
    "] = pm.set_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model_path,l1,l2,loss = 'mae'):\n",
    "            \n",
    "    normalizer = preprocessing.Normalization(axis=-1)\n",
    "    normalizer.adapt(np.array(trfeat))\n",
    "\n",
    "    model = gl.build_dnn_model(\n",
    "        normalizer, learning_rate = 0.01, \n",
    "        layer_1 = l1, layer_2 = l2,loss = loss\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(\n",
    "        trfeat,\n",
    "        trlabs,\n",
    "        validation_split=0.2,\n",
    "        callbacks = [callback],\n",
    "        verbose=0, \n",
    "        epochs=500\n",
    "    )\n",
    "    model_filename = os.path.join(model_path)\n",
    "    model.save(model_filename)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    min_delta = 0.001,\n",
    "    patience = 10,\n",
    "    verbose = 0,\n",
    "    mode = 'auto',\n",
    "    baseline = None,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20619e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(1,5,1):\n",
    "#     l1 = 8\n",
    "#     l2 = 5\n",
    "    if i == 1:\n",
    "        l1 = 10\n",
    "        l2 = 5\n",
    "        \n",
    "    if i == 2:\n",
    "        l1 = 8\n",
    "        l2 = 2\n",
    "        \n",
    "    if i == 3:\n",
    "        l1 = 9\n",
    "        l2 = 5\n",
    "        \n",
    "    if i == 4:\n",
    "        l1 = 6\n",
    "        l2 = 2\n",
    "    set_global_determinism(seed=SEED)\n",
    "    df = gl.coregister_data(data_path,str(i))\n",
    "    df = df.drop(df[df['RGIId'].duplicated(keep = False)].index)\n",
    "    df = df.reset_index().drop('index', axis = 1)\n",
    "    trfeat, tefeat, trlabs, telabs = gl.split_data(df)\n",
    "    print(trfeat)\n",
    "    \n",
    "\n",
    "    model = {}\n",
    "    model_history = {}\n",
    "    normalizer = {}\n",
    "    model_path = os.path.join(\n",
    "        coregistration_testing_path, str(i)\n",
    "    )\n",
    "    model = run_model(model_path,l1,l2)\n",
    "    \n",
    "    rgi_est_pth = os.path.join(model_path, 'rgi_est_raw.pkl')\n",
    "\n",
    "    if os.path.isdir(rgi_est_pth) == False:\n",
    "\n",
    "        RGI = gl.load_RGI(RGI_path)\n",
    "#         RGI['Lmax'] = RGI['Lmax'] / 1e3\n",
    "        rfp = RGI[list(df)[:-1]]\n",
    "\n",
    "        preds = pd.Series(\n",
    "            model.predict(rfp.drop('RGIId',axis = 1)).flatten(), name = i\n",
    "        )\n",
    "        RGI = pd.concat([RGI,preds], axis = 1)\n",
    "        RGI.to_pickle(rgi_est_pth)\n",
    "        print(f'Coregistration {i} predicted RGI')\n",
    "                # RGI = pd.read_pickle('rgi_est_raw.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glacierml (Python3.8.10)",
   "language": "python",
   "name": "glacierml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
